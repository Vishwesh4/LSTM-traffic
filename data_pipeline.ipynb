{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from math import sqrt\n",
    "import math\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from core.data_processor import DataLoader\n",
    "from core.model import Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntill now judgement\\ndate_time: convert to suitable format, doesnt go for prediction \\ndayofweek: add new column signifying day(Monday=0, Sunday=6)\\npeakhours: \\nis_holiday : change all non null to 1\\nwind_speed : to be standardized variable\\nwind_direction: categorical variable, better to put in 60 deg buckets \\nvisibility_in_miles: categorical\\ndew_point: categorical\\ntemperature: replace 0 with mean value and standardize it\\nair_pollution_index : No change, just standardize it\\nhumidity: standardize it\\nrain_p_h: have to think , for now just use as it is\\nsnow_ph: 0 and 1\\nweather_type: label encode\\nweather_description: for now label encode\\nclouds_all : \\ntraffic_volume: to predict\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "till now judgement\n",
    "date_time: convert to suitable format, doesnt go for prediction \n",
    "dayofweek: add new column signifying day(Monday=0, Sunday=6)\n",
    "peakhours: \n",
    "is_holiday : change all non null to 1\n",
    "wind_speed : to be standardized variable\n",
    "wind_direction: categorical variable, better to put in 60 deg buckets \n",
    "visibility_in_miles: categorical\n",
    "dew_point: categorical\n",
    "temperature: replace 0 with mean value and standardize it\n",
    "air_pollution_index : No change, just standardize it\n",
    "humidity: standardize it\n",
    "rain_p_h: have to think , for now just use as it is\n",
    "snow_ph: 0 and 1\n",
    "weather_type: label encode\n",
    "weather_description: for now label encode\n",
    "clouds_all : \n",
    "traffic_volume: to predict\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawdata = pd.read_csv(\"./DataSets/Train.csv\")\n",
    "df_test = pd.read_csv(\"./DataSets/Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>air_pollution_index</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>visibility_in_miles</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rain_p_h</th>\n",
       "      <th>snow_p_h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_type</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-02 09:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>121</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>288.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>5545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-02 10:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>178</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>289.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>4516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-02 11:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>113</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>329</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>289.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-02 12:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>20</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>329</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>290.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>5026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-02 13:00:00</td>\n",
       "      <td>None</td>\n",
       "      <td>281</td>\n",
       "      <td>65</td>\n",
       "      <td>3</td>\n",
       "      <td>329</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>291.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>Clouds</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>4918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_time is_holiday  air_pollution_index  humidity  wind_speed  \\\n",
       "0  2012-10-02 09:00:00       None                  121        89           2   \n",
       "1  2012-10-02 10:00:00       None                  178        67           3   \n",
       "2  2012-10-02 11:00:00       None                  113        66           3   \n",
       "3  2012-10-02 12:00:00       None                   20        66           3   \n",
       "4  2012-10-02 13:00:00       None                  281        65           3   \n",
       "\n",
       "   wind_direction  visibility_in_miles  dew_point  temperature  rain_p_h  \\\n",
       "0             329                    1          1       288.28       0.0   \n",
       "1             330                    1          1       289.36       0.0   \n",
       "2             329                    2          2       289.58       0.0   \n",
       "3             329                    5          5       290.13       0.0   \n",
       "4             329                    7          7       291.14       0.0   \n",
       "\n",
       "   snow_p_h  clouds_all weather_type weather_description  traffic_volume  \n",
       "0       0.0          40       Clouds    scattered clouds            5545  \n",
       "1       0.0          75       Clouds       broken clouds            4516  \n",
       "2       0.0          90       Clouds     overcast clouds            4767  \n",
       "3       0.0          90       Clouds     overcast clouds            5026  \n",
       "4       0.0          75       Clouds       broken clouds            4918  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata.date_time = pd.to_datetime(rawdata['date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(rawdata):\n",
    "    df = rawdata.copy()\n",
    "    #day of week, we have less traffic during saturdays or sundays\n",
    "    df['dayofweek'] = rawdata.date_time.dt.dayofweek\n",
    "    df['month'] = rawdata.date_time.dt.month\n",
    "    #hours\n",
    "    bins = [-0.1,6,12,18,24]\n",
    "    labels = [0,1,2,3]\n",
    "    df['hour']= pd.cut(rawdata['date_time'].dt.hour, bins=bins, labels=labels)\n",
    "    #is_holiday\n",
    "    df['is_holiday'] = (rawdata.is_holiday!='None')*1\n",
    "    A = df.loc[df.is_holiday==1,'date_time']\n",
    "    for items in A:\n",
    "        df.loc[(df.date_time.dt.year==items.year) & (df.date_time.dt.month==items.month) & (df.date_time.dt.day==items.day),'is_holiday'] = 1\n",
    "    #wind_direction\n",
    "    bins = [-0.1, 60, 120, 180, 240, 300, 360]\n",
    "    labels = [0,1,2,3,4,5]\n",
    "    df['wind_direction']= pd.cut(rawdata['wind_direction'], bins=bins, labels=labels)\n",
    "    #temperature\n",
    "    df.loc[rawdata.temperature==0,'temperature'] = np.mean(rawdata.loc[rawdata.temperature!=0,'temperature'])\n",
    "    #snow_p_h\n",
    "    df['snow_p_h'] = (rawdata.snow_p_h!=0)*1\n",
    "    #weather label encode\n",
    "    #Encoding features\n",
    "    lb_weather = LabelEncoder()\n",
    "    df['weather_type'] = lb_weather.fit_transform(rawdata['weather_type'])\n",
    "    lb_weather_des = LabelEncoder()\n",
    "    df['weather_description'] = lb_weather_des.fit_transform(rawdata['weather_description'])\n",
    "    #standardizing\n",
    "    sc = MinMaxScaler()\n",
    "    std_cols = ['temperature','air_pollution_index','humidity','wind_speed','clouds_all']\n",
    "    sc_traffic = MinMaxScaler()\n",
    "    df[\"traffic_volume\"] = sc_traffic.fit_transform(np.array(rawdata[\"traffic_volume\"]).reshape(-1,1))\n",
    "#     mean = rawdata[std_cols].mean()\n",
    "#     std = rawdata[std_cols].std()\n",
    "    df[std_cols] = sc.fit_transform(rawdata[std_cols])\n",
    "    return df,(lb_weather,lb_weather_des),(std_cols,sc,sc_traffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df,encoders,stats = preprocessing(rawdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>air_pollution_index</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>visibility_in_miles</th>\n",
       "      <th>dew_point</th>\n",
       "      <th>temperature</th>\n",
       "      <th>rain_p_h</th>\n",
       "      <th>snow_p_h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_type</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>traffic_volume</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33750.000000</td>\n",
       "      <td>33750.000000</td>\n",
       "      <td>33750.000000</td>\n",
       "      <td>33750.000000</td>\n",
       "      <td>33750.000000</td>\n",
       "      <td>33750.000000</td>\n",
       "      <td>33750.000000</td>\n",
       "      <td>33750.000000</td>\n",
       "      <td>33750.000000</td>\n",
       "      <td>33750.000000</td>\n",
       "      <td>33750.000000</td>\n",
       "      <td>33750.000000</td>\n",
       "      <td>33750.000000</td>\n",
       "      <td>33750.000000</td>\n",
       "      <td>33750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.028859</td>\n",
       "      <td>0.501181</td>\n",
       "      <td>0.669069</td>\n",
       "      <td>0.211137</td>\n",
       "      <td>4.989748</td>\n",
       "      <td>4.989748</td>\n",
       "      <td>0.908609</td>\n",
       "      <td>0.448739</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.504588</td>\n",
       "      <td>2.520000</td>\n",
       "      <td>15.959170</td>\n",
       "      <td>0.445071</td>\n",
       "      <td>2.982667</td>\n",
       "      <td>6.407674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.167413</td>\n",
       "      <td>0.289742</td>\n",
       "      <td>0.193704</td>\n",
       "      <td>0.128487</td>\n",
       "      <td>2.570021</td>\n",
       "      <td>2.570021</td>\n",
       "      <td>0.043522</td>\n",
       "      <td>53.526500</td>\n",
       "      <td>0.043165</td>\n",
       "      <td>0.388717</td>\n",
       "      <td>2.739005</td>\n",
       "      <td>9.081681</td>\n",
       "      <td>0.273556</td>\n",
       "      <td>2.005717</td>\n",
       "      <td>3.543241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252595</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.881521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.160062</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.501730</td>\n",
       "      <td>0.678161</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.908870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.458104</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.754325</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.942837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.676648</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9831.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         is_holiday  air_pollution_index      humidity    wind_speed  \\\n",
       "count  33750.000000         33750.000000  33750.000000  33750.000000   \n",
       "mean       0.028859             0.501181      0.669069      0.211137   \n",
       "std        0.167413             0.289742      0.193704      0.128487   \n",
       "min        0.000000             0.000000      0.000000      0.000000   \n",
       "25%        0.000000             0.252595      0.540230      0.125000   \n",
       "50%        0.000000             0.501730      0.678161      0.187500   \n",
       "75%        0.000000             0.754325      0.827586      0.312500   \n",
       "max        1.000000             1.000000      1.000000      1.000000   \n",
       "\n",
       "       visibility_in_miles     dew_point   temperature      rain_p_h  \\\n",
       "count         33750.000000  33750.000000  33750.000000  33750.000000   \n",
       "mean              4.989748      4.989748      0.908609      0.448739   \n",
       "std               2.570021      2.570021      0.043522     53.526500   \n",
       "min               1.000000      1.000000      0.000000      0.000000   \n",
       "25%               3.000000      3.000000      0.881521      0.000000   \n",
       "50%               5.000000      5.000000      0.908870      0.000000   \n",
       "75%               7.000000      7.000000      0.942837      0.000000   \n",
       "max               9.000000      9.000000      1.000000   9831.300000   \n",
       "\n",
       "           snow_p_h    clouds_all  weather_type  weather_description  \\\n",
       "count  33750.000000  33750.000000  33750.000000         33750.000000   \n",
       "mean       0.001867      0.504588      2.520000            15.959170   \n",
       "std        0.043165      0.388717      2.739005             9.081681   \n",
       "min        0.000000      0.000000      0.000000             0.000000   \n",
       "25%        0.000000      0.010000      0.000000             7.000000   \n",
       "50%        0.000000      0.640000      1.000000            17.000000   \n",
       "75%        0.000000      0.900000      5.000000            24.000000   \n",
       "max        1.000000      1.000000     10.000000            37.000000   \n",
       "\n",
       "       traffic_volume     dayofweek         month  \n",
       "count    33750.000000  33750.000000  33750.000000  \n",
       "mean         0.445071      2.982667      6.407674  \n",
       "std          0.273556      2.005717      3.543241  \n",
       "min          0.000000      0.000000      1.000000  \n",
       "25%          0.160062      1.000000      3.000000  \n",
       "50%          0.458104      3.000000      6.000000  \n",
       "75%          0.676648      5.000000     10.000000  \n",
       "max          1.000000      6.000000     12.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'date_time', u'is_holiday', u'air_pollution_index', u'humidity',\n",
       "       u'wind_speed', u'wind_direction', u'visibility_in_miles', u'dew_point',\n",
       "       u'temperature', u'rain_p_h', u'snow_p_h', u'clouds_all',\n",
       "       u'weather_type', u'weather_description', u'traffic_volume',\n",
       "       u'dayofweek', u'month', u'hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving as CSV...\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33750 entries, 0 to 33749\n",
      "Data columns (total 18 columns):\n",
      "date_time              33750 non-null datetime64[ns]\n",
      "is_holiday             33750 non-null int64\n",
      "air_pollution_index    33750 non-null float64\n",
      "humidity               33750 non-null float64\n",
      "wind_speed             33750 non-null float64\n",
      "wind_direction         33750 non-null category\n",
      "visibility_in_miles    33750 non-null int64\n",
      "dew_point              33750 non-null int64\n",
      "temperature            33750 non-null float64\n",
      "rain_p_h               33750 non-null float64\n",
      "snow_p_h               33750 non-null int64\n",
      "clouds_all             33750 non-null float64\n",
      "weather_type           33750 non-null int64\n",
      "weather_description    33750 non-null int64\n",
      "traffic_volume         33750 non-null float64\n",
      "dayofweek              33750 non-null int64\n",
      "month                  33750 non-null int64\n",
      "hour                   33750 non-null category\n",
      "dtypes: category(2), datetime64[ns](1), float64(7), int64(8)\n",
      "memory usage: 4.2 MB\n"
     ]
    }
   ],
   "source": [
    "#saving file for easy training purpose\n",
    "print('Saving as CSV...')\n",
    "df.to_csv('clean_train.csv',index=False)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 24, 30)            5760      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 24, 30)            0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 24, 40)            11360     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 40)                12960     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 30,121\n",
      "Trainable params: 30,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[Model] Model Compiled\n",
      "Time taken: 0:00:03.332258\n",
      "[Model] Loading model from file ./saved_models/28072019-004141-e50.h5\n",
      "[Model] Training Started\n",
      "[Model] 150 epochs, 64 batch size, 421.0 batches per epoch\n",
      "Epoch 1/150\n",
      "421/421 [==============================] - 95s 225ms/step - loss: 12216769.6431 - mean_absolute_error: 2879.07710s - loss: 12221018.7884 - mean_absolute_error: 2879.\n",
      "Epoch 2/150\n",
      "421/421 [==============================] - 89s 211ms/step - loss: 12131189.3727 - mean_absolute_error: 2867.2128\n",
      "Epoch 3/150\n",
      "421/421 [==============================] - 88s 209ms/step - loss: 12040581.2216 - mean_absolute_error: 2854.0964\n",
      "Epoch 4/150\n",
      "421/421 [==============================] - 87s 207ms/step - loss: 11953649.6693 - mean_absolute_error: 2841.8288\n",
      "Epoch 5/150\n",
      "421/421 [==============================] - 87s 207ms/step - loss: 11865332.3814 - mean_absolute_error: 2829.2444\n",
      "Epoch 6/150\n",
      "421/421 [==============================] - 88s 210ms/step - loss: 11773792.4133 - mean_absolute_error: 2816.5790\n",
      "Epoch 7/150\n",
      "421/421 [==============================] - 88s 208ms/step - loss: 11682825.0361 - mean_absolute_error: 2804.0346\n",
      "Epoch 8/150\n",
      "421/421 [==============================] - 88s 210ms/step - loss: 11607582.9004 - mean_absolute_error: 2793.7140\n",
      "Epoch 9/150\n",
      "421/421 [==============================] - 88s 208ms/step - loss: 11516202.5998 - mean_absolute_error: 2780.6925\n",
      "Epoch 10/150\n",
      "421/421 [==============================] - 100s 238ms/step - loss: 11420477.5649 - mean_absolute_error: 2768.0133s - loss: 11522428.30\n",
      "Epoch 11/150\n",
      "421/421 [==============================] - 87s 207ms/step - loss: 11347109.4232 - mean_absolute_error: 2758.0127\n",
      "Epoch 12/150\n",
      "421/421 [==============================] - 87s 206ms/step - loss: 11244133.6561 - mean_absolute_error: 2743.9041\n",
      "Epoch 13/150\n",
      "421/421 [==============================] - 87s 206ms/step - loss: 11173717.4660 - mean_absolute_error: 2734.0465\n",
      "Epoch 14/150\n",
      "421/421 [==============================] - 87s 207ms/step - loss: 11070993.5737 - mean_absolute_error: 2719.9660\n",
      "Epoch 15/150\n",
      "421/421 [==============================] - 88s 208ms/step - loss: 11006376.3515 - mean_absolute_error: 2711.5498\n",
      "Epoch 16/150\n",
      "421/421 [==============================] - 89s 212ms/step - loss: 10909751.4058 - mean_absolute_error: 2698.3055\n",
      "Epoch 17/150\n",
      "421/421 [==============================] - 88s 209ms/step - loss: 10826322.8062 - mean_absolute_error: 2686.7369\n",
      "Epoch 18/150\n",
      "421/421 [==============================] - 87s 207ms/step - loss: 10753935.7356 - mean_absolute_error: 2677.5400\n",
      "Epoch 19/150\n",
      "421/421 [==============================] - 87s 207ms/step - loss: 10658115.4187 - mean_absolute_error: 2664.5791\n",
      "Epoch 20/150\n",
      "421/421 [==============================] - 87s 207ms/step - loss: 10603291.6615 - mean_absolute_error: 2659.3842\n",
      "Epoch 21/150\n",
      "421/421 [==============================] - 87s 207ms/step - loss: 10504534.2171 - mean_absolute_error: 2644.4550\n",
      "Epoch 22/150\n",
      "421/421 [==============================] - 88s 209ms/step - loss: 10431449.3778 - mean_absolute_error: 2635.7462\n",
      "Epoch 23/150\n",
      "421/421 [==============================] - 88s 210ms/step - loss: 10340078.0096 - mean_absolute_error: 2622.7221\n",
      "Epoch 24/150\n",
      "421/421 [==============================] - 88s 208ms/step - loss: 10287783.8149 - mean_absolute_error: 2617.6631\n",
      "Epoch 25/150\n",
      "421/421 [==============================] - 88s 209ms/step - loss: 10180423.6880 - mean_absolute_error: 2600.3526\n",
      "Epoch 26/150\n",
      "421/421 [==============================] - 89s 211ms/step - loss: 10139839.1247 - mean_absolute_error: 2598.69025s - loss: 10083098.3715 - me\n",
      "Epoch 27/150\n",
      "421/421 [==============================] - 88s 210ms/step - loss: 10023114.9190 - mean_absolute_error: 2581.8140\n",
      "Epoch 28/150\n",
      "421/421 [==============================] - 88s 209ms/step - loss: 9966621.4706 - mean_absolute_error: 2576.8079\n",
      "Epoch 29/150\n",
      "421/421 [==============================] - 90s 213ms/step - loss: 9860145.7716 - mean_absolute_error: 2554.1963\n",
      "Epoch 30/150\n",
      "421/421 [==============================] - 88s 210ms/step - loss: 9795773.0244 - mean_absolute_error: 2547.5388\n",
      "Epoch 31/150\n",
      "421/421 [==============================] - 88s 210ms/step - loss: 9710156.7050 - mean_absolute_error: 2526.8533\n",
      "Epoch 32/150\n",
      "421/421 [==============================] - 89s 210ms/step - loss: 9626889.8732 - mean_absolute_error: 2510.5055\n",
      "Epoch 33/150\n",
      "421/421 [==============================] - 88s 210ms/step - loss: 9556262.1956 - mean_absolute_error: 2496.9260\n",
      "Epoch 34/150\n",
      "421/421 [==============================] - 89s 211ms/step - loss: 9469730.9941 - mean_absolute_error: 2482.8682\n",
      "Epoch 35/150\n",
      "421/421 [==============================] - 88s 210ms/step - loss: 9413873.1261 - mean_absolute_error: 2476.1565\n",
      "Epoch 36/150\n",
      "421/421 [==============================] - 89s 212ms/step - loss: 9319525.6617 - mean_absolute_error: 2459.3365\n",
      "Epoch 37/150\n",
      "421/421 [==============================] - 88s 210ms/step - loss: 9243116.9036 - mean_absolute_error: 2446.7702\n",
      "Epoch 38/150\n",
      "421/421 [==============================] - 89s 212ms/step - loss: 9172649.2543 - mean_absolute_error: 2432.8428\n",
      "Epoch 39/150\n",
      "421/421 [==============================] - 89s 212ms/step - loss: 9094302.4542 - mean_absolute_error: 2419.9457\n",
      "Epoch 40/150\n",
      "421/421 [==============================] - 89s 210ms/step - loss: 9021237.5075 - mean_absolute_error: 2407.2418\n",
      "Epoch 41/150\n",
      "421/421 [==============================] - 90s 214ms/step - loss: 8932122.4335 - mean_absolute_error: 2395.5063\n",
      "Epoch 42/150\n",
      "421/421 [==============================] - 90s 214ms/step - loss: 8885449.4130 - mean_absolute_error: 2389.1270s - loss: 8830485\n",
      "Epoch 43/150\n",
      "421/421 [==============================] - 91s 217ms/step - loss: 8790656.1678 - mean_absolute_error: 2373.4256s - loss: 8776306.3170 - mean_absolute_error: 237\n",
      "Epoch 44/150\n",
      "421/421 [==============================] - 90s 215ms/step - loss: 8734827.8021 - mean_absolute_error: 2363.5482\n",
      "Epoch 45/150\n",
      "421/421 [==============================] - 90s 215ms/step - loss: 8632735.6646 - mean_absolute_error: 2346.9951\n",
      "Epoch 46/150\n",
      "421/421 [==============================] - 90s 214ms/step - loss: 8591439.9717 - mean_absolute_error: 2343.6219s - loss:\n",
      "Epoch 47/150\n",
      "421/421 [==============================] - 90s 214ms/step - loss: 8501764.9981 - mean_absolute_error: 2327.0635\n",
      "Epoch 48/150\n",
      "421/421 [==============================] - 90s 215ms/step - loss: 8439481.8376 - mean_absolute_error: 2316.8437\n",
      "Epoch 49/150\n",
      "421/421 [==============================] - 91s 216ms/step - loss: 8353444.2727 - mean_absolute_error: 2301.0878\n",
      "Epoch 50/150\n",
      "421/421 [==============================] - 91s 216ms/step - loss: 8306691.1248 - mean_absolute_error: 2298.5122\n",
      "Epoch 51/150\n",
      "421/421 [==============================] - 90s 213ms/step - loss: 8227073.8114 - mean_absolute_error: 2287.9254\n",
      "Epoch 52/150\n",
      "421/421 [==============================] - 90s 215ms/step - loss: 8162993.0027 - mean_absolute_error: 2278.0870\n",
      "Epoch 53/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "421/421 [==============================] - 83s 197ms/step - loss: 8107829.8680 - mean_absolute_error: 2268.0068\n",
      "Epoch 54/150\n",
      "421/421 [==============================] - 83s 197ms/step - loss: 8009978.4211 - mean_absolute_error: 2250.8579\n",
      "Epoch 55/150\n",
      "421/421 [==============================] - 84s 198ms/step - loss: 7950273.3306 - mean_absolute_error: 2239.7177\n",
      "Epoch 56/150\n",
      "421/421 [==============================] - 84s 199ms/step - loss: 7875406.7896 - mean_absolute_error: 2226.8105\n",
      "Epoch 57/150\n",
      "421/421 [==============================] - 85s 202ms/step - loss: 7821247.7623 - mean_absolute_error: 2222.6435\n",
      "Epoch 58/150\n",
      "421/421 [==============================] - 83s 197ms/step - loss: 7733566.1519 - mean_absolute_error: 2204.4345s - loss: 7764976.8849 - mean_absolut\n",
      "Epoch 59/150\n",
      "421/421 [==============================] - 83s 198ms/step - loss: 7684935.4193 - mean_absolute_error: 2198.7738\n",
      "Epoch 60/150\n",
      "421/421 [==============================] - 84s 199ms/step - loss: 7603082.6396 - mean_absolute_error: 2182.8767\n",
      "Epoch 61/150\n",
      "421/421 [==============================] - 84s 199ms/step - loss: 7553643.8776 - mean_absolute_error: 2184.1245\n",
      "Epoch 62/150\n",
      "421/421 [==============================] - 84s 199ms/step - loss: 7468829.8698 - mean_absolute_error: 2161.6236\n",
      "Epoch 63/150\n",
      "421/421 [==============================] - 85s 201ms/step - loss: 7418354.5577 - mean_absolute_error: 2153.6998\n",
      "Epoch 64/150\n",
      "421/421 [==============================] - 83s 198ms/step - loss: 7340911.6155 - mean_absolute_error: 2139.9754\n",
      "Epoch 65/150\n",
      " 94/421 [=====>........................] - ETA: 1:05 - loss: 7120785.0053 - mean_absolute_error: 2121.0199"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9068a55add37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'save_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vishwesh/Projects/Machine Learning/traffic_prediction/core/model.pyc\u001b[0m in \u001b[0;36mtrain_generator\u001b[0;34m(self, data_gen, epochs, batch_size, steps_per_epoch, save_dir)\u001b[0m\n\u001b[1;32m     58\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \t\t)\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vishwesh/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vishwesh/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vishwesh/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training_generator.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#running model\n",
    "configs = json.load(open('config.json', 'r'))\n",
    "if not os.path.exists(configs['model']['save_dir']): os.makedirs(configs['model']['save_dir'])\n",
    "\n",
    "data = DataLoader(\n",
    "    configs['data']['filename'],\n",
    "    configs['data']['train_test_split'],\n",
    "    configs['data']['columns']\n",
    ")\n",
    "\n",
    "model = Model()\n",
    "model.build_model(configs)\n",
    "model.load_model('./saved_models/28072019-004141-e50.h5')\n",
    "\n",
    "# out-of memory generative training\n",
    "steps_per_epoch = math.ceil((data.len_train - configs['data']['sequence_length']) / configs['training']['batch_size'])\n",
    "model.train_generator(\n",
    "    data_gen=data.generate_train_batch(\n",
    "        seq_len=configs['data']['sequence_length'],\n",
    "        batch_size=configs['training']['batch_size'],\n",
    "        normalise=configs['data']['normalise']\n",
    "    ),\n",
    "    epochs=configs['training']['epochs'],\n",
    "    batch_size=configs['training']['batch_size'],\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    save_dir=configs['model']['save_dir']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 24, 30)            5760      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 30)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 24, 40)            11360     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 40)                12960     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 30,121\n",
      "Trainable params: 30,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[Model] Model Compiled\n",
      "Time taken: 0:00:02.386827\n",
      "[Model] Loading model from file ./saved_models/28072019-004141-e50.h5\n"
     ]
    }
   ],
   "source": [
    "#Loading model if you didnt train\n",
    "#running model\n",
    "configs = json.load(open('config.json', 'r'))\n",
    "if not os.path.exists(configs['model']['save_dir']): os.makedirs(configs['model']['save_dir'])\n",
    "\n",
    "data = DataLoader(\n",
    "    configs['data']['filename'],\n",
    "    configs['data']['train_test_split'],\n",
    "    configs['data']['columns']\n",
    ")\n",
    "\n",
    "model = Model()\n",
    "model.build_model(configs)\n",
    "model.load_model('./saved_models/28072019-004141-e50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test data preperation\n",
    "df_test.date_time = pd.to_datetime(df_test['date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepping_test(rawdata,stats,encoder):\n",
    "    df = rawdata.copy()\n",
    "    #day of week, we have less traffic during saturdays or sundays\n",
    "    df['dayofweek'] = rawdata.date_time.dt.dayofweek\n",
    "    df['month'] = rawdata.date_time.dt.month\n",
    "    #hours\n",
    "    bins = [-0.1,6,12,18,24]\n",
    "    labels = [0,1,2,3]\n",
    "    df['hour']= pd.cut(rawdata['date_time'].dt.hour, bins=bins, labels=labels)\n",
    "    #is_holiday\n",
    "    df['is_holiday'] = (rawdata.is_holiday!='None')*1\n",
    "    A = df.loc[df.is_holiday==1,'date_time']\n",
    "    for items in A:\n",
    "        df.loc[(df.date_time.dt.year==items.year) & (df.date_time.dt.month==items.month) & (df.date_time.dt.day==items.day),'is_holiday'] = 1\n",
    "    #wind_direction\n",
    "    bins = [-0.1, 60, 120, 180, 240, 300, 360]\n",
    "    labels = [0,1,2,3,4,5]\n",
    "    df['wind_direction']= pd.cut(rawdata['wind_direction'], bins=bins, labels=labels)\n",
    "    #temperature\n",
    "    df.loc[rawdata.temperature==0,'temperature'] = np.mean(rawdata.loc[rawdata.temperature!=0,'temperature'])\n",
    "    #snow_p_h\n",
    "    df['snow_p_h'] = (rawdata.snow_p_h!=0)*1\n",
    "    #weather label encode\n",
    "    #Encoding features\n",
    "    df['weather_type'] = encoder[0].transform(rawdata['weather_type'])\n",
    "    df['weather_description'] = encoder[1].transform(rawdata['weather_description'])\n",
    "    #normalizing, not including traffic volume\n",
    "    std_cols = stats[0]\n",
    "#     mean = stats[1][:-1]\n",
    "#     std = stats[2][:-1]\n",
    "    df[std_cols] = stats[1].transform(rawdata[std_cols])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_prepped = prepping_test(df_test,stats,encoders)\n",
    "df_test_prepped[\"traffic_volume\"] = np.NaN\n",
    "data_to_attach=configs[\"data\"][\"sequence_length\"]-1\n",
    "df_test_prepped=pd.concat([df.iloc[-data_to_attach:],df_test_prepped],axis=0)\n",
    "df_test_prepped.reset_index(drop=True)\n",
    "df_test_prepped.to_csv(\"./clean_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_window(data_train,i, seq_len):\n",
    "    '''Generates the next data window from the given index location i'''\n",
    "    window = data_train[i:i+seq_len]\n",
    "    x = window[:-1]\n",
    "    y = window[-1, [0]]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I generate data window, preditict and update and repeat\n",
    "for i in range(len(df_test_prepped)-configs['data']['sequence_length'] + 1):\n",
    "    print(\"Done {}/{}\".format(i,len(df_test_prepped)-configs['data']['sequence_length'])+1)\n",
    "    x_test,y = next_window(df_test_prepped.get(configs[\"data\"][\"columns\"]).values,i,configs['data']['sequence_length'])    \n",
    "    pred = model.model.predict(x_test[np.newaxis])[0][0]\n",
    "    df_test_prepped.traffic_volume[24+i] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#de normalizing \n",
    "df_test_prepped.traffic_volume = stats[2].inverse_transform(np.array(df_test_prepped.traffic_volume).reshape(-1,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
